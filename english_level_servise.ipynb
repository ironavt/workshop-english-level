{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dd4455-a8a8-4937-b257-ef3c861491ef",
   "metadata": {},
   "source": [
    "# English level servise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93058f4c-fcd7-4cbf-9fdb-bd1add24e976",
   "metadata": {},
   "source": [
    "This notebook grabs all the files from `Sample_subs` folder and labels them using the model saved in `english_level_model.pkl` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a534e-00b4-42d2-ae00-425ed81eb76b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21b15e-c7c5-4cc7-82b9-717af2c7bef3",
   "metadata": {},
   "source": [
    "Here's imports and functions we could use from previous notebooks. It's better to get them all into a separate `.py` file so I can import them without copy/pasting the code. Oy-vey! No time for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c158a8-d106-44c4-adb5-8f05f75320ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to work with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d75130-6616-4af4-9bfb-8f2fe67de456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to work with files\n",
    "import os\n",
    "import pysrt # https://github.com/byroot/pysrt\n",
    "import chardet # detect encoding\n",
    "import codecs # decode files\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02270a62-6b0f-42af-a7aa-a392c929a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural language toolkit\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17401135-20e5-496b-835a-66148699c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0182956c-66c9-4491-9725-8b219715620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "UTF8_SUBFOLDER = r'/utf-8'\n",
    "\n",
    "RND_STATE = 1337\n",
    "\n",
    "PATH_MODEL=r'./english_level_model.pkl'\n",
    "PATH_SUBS_SAMPLE=r'./Sample_subs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935649fc-321d-4897-850c-36646b24b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for text processing\n",
    "HTML = re.compile(r'<.*?>')\n",
    "TAG = re.compile(r'{.*?}')\n",
    "COMMENTS = re.compile(r'[\\(\\[][A-Z ]+[\\)\\]]')\n",
    "LETTERS = re.compile(r'[^a-zA-Z\\'.,!? ]')\n",
    "SPACES = re.compile(r'([ ])\\1+')\n",
    "DOTS = re.compile(r'[\\.]+')\n",
    "\n",
    "ONLY_WORDS = re.compile(r'[.,!?]|(?:\\'[a-z]*)') # for BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d09294f9-0b1b-4555-bcb8-3b0627d34384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns encoding of the file\n",
    "def encoding_detector(file_path):\n",
    "    # read the first 1000 bytes of the file\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read(1000)\n",
    "    # detect the encoding of the file\n",
    "    result = chardet.detect(raw_data)\n",
    "    encoding = result['encoding']\n",
    "    file.close()\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adac54e2-04f0-48d3-bebc-59b7baca8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes folder, gets all .srt files , encodes them to utf-8\n",
    "# and puts them into /utf-8 subfolder\n",
    "def folder_to_utf(folder_path):\n",
    "    # create a utf-8 subfolder\n",
    "    os.makedirs(os.path.join(folder_path, 'utf-8'), exist_ok=True)\n",
    "\n",
    "    # loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.srt'):\n",
    "            # define the file paths\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            new_file_path = os.path.join(folder_path, 'utf-8', filename)\n",
    "\n",
    "            # open the file and read its contents\n",
    "            with codecs.open(file_path, 'r', encoding=encoding_detector(file_path), errors='replace') as file:\n",
    "                contents = file.read()\n",
    "                file.close()\n",
    "\n",
    "            # write the contents to a new file with UTF-8 encoding\n",
    "            with codecs.open(new_file_path, 'w', encoding='UTF-8', errors='replace') as new_file:\n",
    "                new_file.write(contents)\n",
    "                new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1999b76d-b437-44d1-b32a-308144b4955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re text cleaner\n",
    "def re_clean_subs(subs):\n",
    "    txt = re.sub(HTML, ' ', subs) # html to space\n",
    "    txt = re.sub(TAG, ' ', txt) # tags to space\n",
    "    txt = re.sub(COMMENTS, ' ', txt) # commentaries to space\n",
    "    txt = re.sub(LETTERS, ' ', txt) # non-char to space\n",
    "    txt = re.sub(SPACES, r'\\1', txt) # leading spaces to one space\n",
    "    txt = re.sub(DOTS, r'.', txt)  # ellipsis to dot\n",
    "    txt = txt.encode('ascii', 'ignore').decode() # clear non-ascii symbols   \n",
    "    txt = \".\".join(txt.lower().split('.')[1:-1]) # delete the first and the last subtitle (ads)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe3d9238-34dd-4739-abde-42e51d58ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stop words list and creating a lemmatiser object\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "661ea17a-723b-44fe-a84c-c60aa30f39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function executes text preprocessing\n",
    "def text_preprocess_lem(text):\n",
    "    text = re_clean_subs(text) # clean text using RE\n",
    "    tokens = nltk.word_tokenize(text) # tokenisation\n",
    "    text = [word for word in tokens if word not in stop_words] # stop words removal\n",
    "    text = [lemmatizer.lemmatize(word) for word in text] # lemmatising tokens\n",
    "    text = \" \".join(text) # making text from the list\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e7532c-3d42-47e4-954e-466f24b2f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function extracts raw text from .srt file\n",
    "def srt_raw_text(file_path):\n",
    "    try:\n",
    "        subs = pysrt.open(file_path)\n",
    "        return subs.text\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff184f9-eb85-491a-acd3-c1c5151b8a06",
   "metadata": {},
   "source": [
    "## Getting file labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136f8fa-c753-4054-9c68-61a708b1f719",
   "metadata": {},
   "source": [
    "### Prepearing files and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baef79c-c61d-4087-94eb-671f18d04e86",
   "metadata": {},
   "source": [
    "Encode all `.srt` files in directory to `utf-8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b30fb29d-1887-4270-908b-6948976ed593",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_utf(PATH_SUBS_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d88488-34c4-49e5-acb8-5ba964dc455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving path to the folder with reencoded .srt\n",
    "all_subs_path = Path(PATH_SUBS_SAMPLE+UTF8_SUBFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86bb1c0d-4340-4e87-a53c-4595f0f555e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_knights_tale(2001).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\A_knights_tale(2001).srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_and_the_beast(2017).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\Beauty_and_the_beast(2017).srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_fault_in_our_stars(2014).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\The_fault_in_our_stars(2014)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_usual_suspects(1995).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\The_usual_suspects(1995).srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While_You_Were_Sleeping(1995).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\While_You_Were_Sleeping(1995...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  \\\n",
       "0           A_knights_tale(2001).srt   \n",
       "1     Beauty_and_the_beast(2017).srt   \n",
       "2   The_fault_in_our_stars(2014).srt   \n",
       "3       The_usual_suspects(1995).srt   \n",
       "4  While_You_Were_Sleeping(1995).srt   \n",
       "\n",
       "                                           file_path  \n",
       "0         Sample_subs\\utf-8\\A_knights_tale(2001).srt  \n",
       "1   Sample_subs\\utf-8\\Beauty_and_the_beast(2017).srt  \n",
       "2  Sample_subs\\utf-8\\The_fault_in_our_stars(2014)...  \n",
       "3     Sample_subs\\utf-8\\The_usual_suspects(1995).srt  \n",
       "4  Sample_subs\\utf-8\\While_You_Were_Sleeping(1995...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 subtitle files\n"
     ]
    }
   ],
   "source": [
    "# getting df with file names and file paths\n",
    "all_subs_list = [p.name for p in all_subs_path.glob('*.srt')]\n",
    "all_subs_df = pd.DataFrame({'file_name': all_subs_list,\n",
    "                            'file_path': list(all_subs_path.glob('*.srt'))})\n",
    "display(all_subs_df)\n",
    "print(f'Found {all_subs_df.shape[0]} subtitle files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d0bfc93-4e47-4d06-8a6f-4049f8915648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_knights_tale(2001).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\A_knights_tale(2001).srt</td>\n",
       "      <td>Resync: Xenzai[NEF]\\nRETAIL\\nShould we help hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_and_the_beast(2017).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\Beauty_and_the_beast(2017).srt</td>\n",
       "      <td>Once upon a time,\\nin the hidden heart of Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_fault_in_our_stars(2014).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\The_fault_in_our_stars(2014)...</td>\n",
       "      <td>&lt;i&gt;I believe we have a choice in this\\nworld a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_usual_suspects(1995).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\The_usual_suspects(1995).srt</td>\n",
       "      <td>How you doing, Keaton?\\nI can't feel my legs.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While_You_Were_Sleeping(1995).srt</td>\n",
       "      <td>Sample_subs\\utf-8\\While_You_Were_Sleeping(1995...</td>\n",
       "      <td>LUCY: &lt;i&gt;Okay, there are two things that&lt;/i&gt;\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  \\\n",
       "0           A_knights_tale(2001).srt   \n",
       "1     Beauty_and_the_beast(2017).srt   \n",
       "2   The_fault_in_our_stars(2014).srt   \n",
       "3       The_usual_suspects(1995).srt   \n",
       "4  While_You_Were_Sleeping(1995).srt   \n",
       "\n",
       "                                           file_path  \\\n",
       "0         Sample_subs\\utf-8\\A_knights_tale(2001).srt   \n",
       "1   Sample_subs\\utf-8\\Beauty_and_the_beast(2017).srt   \n",
       "2  Sample_subs\\utf-8\\The_fault_in_our_stars(2014)...   \n",
       "3     Sample_subs\\utf-8\\The_usual_suspects(1995).srt   \n",
       "4  Sample_subs\\utf-8\\While_You_Were_Sleeping(1995...   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Resync: Xenzai[NEF]\\nRETAIL\\nShould we help hi...  \n",
       "1  Once upon a time,\\nin the hidden heart of Fran...  \n",
       "2  <i>I believe we have a choice in this\\nworld a...  \n",
       "3  How you doing, Keaton?\\nI can't feel my legs.....  \n",
       "4  LUCY: <i>Okay, there are two things that</i>\\n...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding text to dataframe\n",
    "all_subs_df['raw_text'] = all_subs_df['file_path'].apply(srt_raw_text)\n",
    "all_subs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b2819cb-6e16-4910-baec-02e0875c9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_knights_tale(2001).srt</td>\n",
       "      <td>two minute forfeit . lend u . right . left . d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_and_the_beast(2017).srt</td>\n",
       "      <td>handsome young prince . lived beautiful castle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_fault_in_our_stars(2014).srt</td>\n",
       "      <td>one hand , sugarcoat . way movie romance novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_usual_suspects(1995).srt</td>\n",
       "      <td>keyser . ready ? time ? . started back new yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While_You_Were_Sleeping(1995).srt</td>\n",
       "      <td>n't remember orange . first , remember dad . w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  \\\n",
       "0           A_knights_tale(2001).srt   \n",
       "1     Beauty_and_the_beast(2017).srt   \n",
       "2   The_fault_in_our_stars(2014).srt   \n",
       "3       The_usual_suspects(1995).srt   \n",
       "4  While_You_Were_Sleeping(1995).srt   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  two minute forfeit . lend u . right . left . d...  \n",
       "1  handsome young prince . lived beautiful castle...  \n",
       "2  one hand , sugarcoat . way movie romance novel...  \n",
       "3  keyser . ready ? time ? . started back new yor...  \n",
       "4  n't remember orange . first , remember dad . w...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subs_df['preprocessed_text'] = all_subs_df['raw_text'].apply(text_preprocess_lem)\n",
    "df1 = all_subs_df.drop(columns=['file_path', 'raw_text'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500147a-57be-4c3d-b633-931cf9f8e917",
   "metadata": {},
   "source": [
    "### Vectorising text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07c7171d-f4be-4607-84a2-f4a970dbf7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>bow_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_knights_tale(2001).srt</td>\n",
       "      <td>two minute forfeit . lend u . right . left . d...</td>\n",
       "      <td>two minute forfeit lend u right left dead eh t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_and_the_beast(2017).srt</td>\n",
       "      <td>handsome young prince . lived beautiful castle...</td>\n",
       "      <td>handsome young prince lived beautiful castle p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_fault_in_our_stars(2014).srt</td>\n",
       "      <td>one hand , sugarcoat . way movie romance novel...</td>\n",
       "      <td>one hand sugarcoat way movie romance novel bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_usual_suspects(1995).srt</td>\n",
       "      <td>keyser . ready ? time ? . started back new yor...</td>\n",
       "      <td>keyser ready time started back new york six we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While_You_Were_Sleeping(1995).srt</td>\n",
       "      <td>n't remember orange . first , remember dad . w...</td>\n",
       "      <td>n remember orange first remember dad would get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  \\\n",
       "0           A_knights_tale(2001).srt   \n",
       "1     Beauty_and_the_beast(2017).srt   \n",
       "2   The_fault_in_our_stars(2014).srt   \n",
       "3       The_usual_suspects(1995).srt   \n",
       "4  While_You_Were_Sleeping(1995).srt   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  two minute forfeit . lend u . right . left . d...   \n",
       "1  handsome young prince . lived beautiful castle...   \n",
       "2  one hand , sugarcoat . way movie romance novel...   \n",
       "3  keyser . ready ? time ? . started back new yor...   \n",
       "4  n't remember orange . first , remember dad . w...   \n",
       "\n",
       "                                            bow_text  \n",
       "0  two minute forfeit lend u right left dead eh t...  \n",
       "1  handsome young prince lived beautiful castle p...  \n",
       "2  one hand sugarcoat way movie romance novel bea...  \n",
       "3  keyser ready time started back new york six we...  \n",
       "4  n remember orange first remember dad would get...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leaving only words\n",
    "df1['bow_text'] = df1['preprocessed_text'].apply(lambda x: re.sub(ONLY_WORDS, '', x))\n",
    "df1['bow_text'] = df1['bow_text'].apply(lambda x: re.sub(r'\\s+', ' ', x)) # removing multiple spaces\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4aea04da-f644-4089-9484-6aaf6f948245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x4104 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6810 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting features\n",
    "X1 = df1['bow_text'].copy()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X1)\n",
    "\n",
    "X1 = vectorizer.transform(X1)\n",
    "\n",
    "display(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c787d36-9501-44bd-a88a-e529bdc8bd4e",
   "metadata": {},
   "source": [
    "### Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c00f7ae5-155f-4c2c-b2a5-8ac39780f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(PATH_MODEL, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a64aa52-9d39-4b94-8e57-16a11b6d4daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7016/1193641813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;34m\"\"\"Calculate the posterior log probability of the samples X\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    786\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "labels = model.predict(X1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7ced4-f22c-4375-a954-4e5a38ca1d3a",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedb994-57ac-4a27-8eef-94c26104afa6",
   "metadata": {},
   "source": [
    "That's all for this project so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd89a1f-22f3-45c8-9b7d-dab4b721bb35",
   "metadata": {},
   "source": [
    "I encountered a new problem I yet don't know how to deal with. But I'm out of time so here's all I got so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092a00f-6e4f-4c01-8870-5cd72ebd9a5d",
   "metadata": {},
   "source": [
    "Expierence I gained from this project:\n",
    "* worked with file system and learned how to deal with different encodings\n",
    "* gained some expierence working with text processing libraries\n",
    "* worked with Optuna and CatBoost; didn't get any good result so far"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
